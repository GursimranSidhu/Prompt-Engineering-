{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16ae47bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pvporcupine\n",
      "  Downloading pvporcupine-3.0.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: sounddevice in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.5.2)\n",
      "Requirement already satisfied: CFFI>=1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sounddevice) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from CFFI>=1.0->sounddevice) (2.21)\n",
      "Downloading pvporcupine-3.0.5-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pvporcupine\n",
      "Successfully installed pvporcupine-3.0.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pvporcupine sounddevice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3625a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pvporcupine\n",
    "import sounddevice as sd\n",
    "import struct\n",
    "import threading\n",
    "import time\n",
    "import soundfile as sf\n",
    "import requests\n",
    "import json\n",
    "import threading\n",
    "import io\n",
    "import datetime\n",
    "\n",
    "import pvporcupine\n",
    "\n",
    "ACCESS_KEY = \"EcMe/J73KApZdXoESH0aWLgUkTDbaeGHzMl1wguJ5Ix7p6ggXTdFDQ==\"  # Replace with your key\n",
    "\n",
    "porcupine = pvporcupine.create(\n",
    "    access_key=ACCESS_KEY,\n",
    "    keywords=[\"jarvis\"]  # Or \"jarvis\", \"picovoice\", \"hey google\"\n",
    ")\n",
    "\n",
    "\n",
    "# Flag to trigger your AI pipeline\n",
    "wake_word_detected = False\n",
    "\n",
    "# Audio callback to run in background\n",
    "def audio_callback(indata, frames, time_info, status):\n",
    "    global wake_word_detected\n",
    "    pcm = struct.unpack_from(\"h\" * len(indata), indata)\n",
    "    result = porcupine.process(pcm)\n",
    "    if result >= 0:\n",
    "        print(\"\\nâœ… Wake word detected!\")\n",
    "        wake_word_detected = True\n",
    "\n",
    "# Background listener thread\n",
    "def start_wake_word_listener():\n",
    "    with sd.InputStream(channels=1,\n",
    "                        samplerate=porcupine.sample_rate,\n",
    "                        dtype='int16',\n",
    "                        blocksize=porcupine.frame_length,\n",
    "                        callback=audio_callback):\n",
    "        print(\"ðŸŽ§ Listening for 'computer'... Speak the wake word anytime.\")\n",
    "        while True:\n",
    "            time.sleep(0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9891e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMINI_API_KEY = \"AIzaSyAUJrMKFNR2YgkE22Orzufwo-tD2xggDVk\"\n",
    "ELEVENLABS_API_KEY=\"sk_c642f3c2cca9989f1876b061b32343d7035f9017272f9d41\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "548f0aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_gemini(text):\n",
    "    url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={GEMINI_API_KEY}\"\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"contents\": [\n",
    "            {\n",
    "                \"parts\": [{\"text\": text}]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "    print(\"Gemini API status:\", response.status_code)\n",
    "\n",
    "    try:\n",
    "        result = response.json()\n",
    "        if 'candidates' in result:\n",
    "            return result['candidates'][0]['content']['parts'][0]['text']\n",
    "        else:\n",
    "            print(\"âŒ No 'candidates' found in Gemini response.\")\n",
    "            return \"Gemini response failed.\"\n",
    "    except Exception as e:\n",
    "        print(\"âŒ Error parsing Gemini response:\", e)\n",
    "        return \"Gemini response failed.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffca253c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_whisper(filename):\n",
    "    url = \"https://api-inference.huggingface.co/models/openai/whisper-large-v3\"\n",
    "    headers = {\n",
    "        \"Authorization\": \"Bearer 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\",  # Replace with your token\n",
    "        \"Content-Type\": \"audio/wav\"\n",
    "    }\n",
    "\n",
    "    with open(filename, \"rb\") as f:\n",
    "        audio_data = f.read()\n",
    "\n",
    "    response = requests.post(url, headers=headers, data=audio_data)\n",
    "\n",
    "    print(\"ðŸ“¡ Whisper API status:\", response.status_code)\n",
    "    print(\"ðŸ“¨ Whisper API raw response:\", response.text[:500])  # print first 500 chars\n",
    "\n",
    "    try:\n",
    "        result = response.json()\n",
    "        if \"text\" in result:\n",
    "            return result[\"text\"]\n",
    "        else:\n",
    "            print(\"âŒ No 'text' field found in response.\")\n",
    "            return \"Transcription failed.\"\n",
    "    except Exception as e:\n",
    "        print(\"âŒ Error parsing Whisper response:\", e)\n",
    "        return \"Transcription failed.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5be9e23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak_elevenlabs(text):\n",
    "    import datetime\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"ai_response_{timestamp}.mp3\"\n",
    "\n",
    "    url = \"https://api.elevenlabs.io/v1/text-to-speech/TxGEqnHWrfWFTfGW9XjX\"\n",
    "    headers = {\n",
    "        \"accept\": \"audio/mpeg\",\n",
    "        \"xi-api-key\": ELEVENLABS_API_KEY,  # ðŸ”‘ Define your API key earlier in your code\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"text\": text,\n",
    "        \"model_id\": \"eleven_monolingual_v1\",\n",
    "        \"voice_settings\": {\n",
    "            \"stability\": 0.5,\n",
    "            \"similarity_boost\": 0.75\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Save audio\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"âœ… Audio saved as: {filename}\")\n",
    "\n",
    "        # Play audio\n",
    "        audio_stream = io.BytesIO(response.content)\n",
    "        with sf.SoundFile(audio_stream) as f:\n",
    "            audio_data = f.read(dtype=\"float32\")\n",
    "            sd.play(audio_data, samplerate=f.samplerate)\n",
    "            sd.wait()\n",
    "    else:\n",
    "        print(\"âŒ ElevenLabs API failed:\", response.status_code)\n",
    "        print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "275787a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ai_pipeline():\n",
    "    global wake_word_detected\n",
    "    while True:\n",
    "        if wake_word_detected:\n",
    "            wake_word_detected = False  # Reset flag\n",
    "            \n",
    "            # RECORD USER SPEECH\n",
    "            print(\"ðŸŽ¤ Recording voice for 5 seconds...\")\n",
    "            duration = 5\n",
    "            fs = 44100\n",
    "            recording = sd.rec(int(duration * fs), samplerate=fs, channels=1)\n",
    "            sd.wait()\n",
    "            filename = \"user_input.wav\"\n",
    "            sf.write(filename, recording, fs)\n",
    "            \n",
    "            # TRANSCRIBE USING WHISPER (you already have this code)\n",
    "            user_text = transcribe_whisper(filename)\n",
    "            print(\"ðŸ“ Transcribed:\", user_text)\n",
    "            \n",
    "            # GENERATE RESPONSE (Gemini)\n",
    "            ai_text = query_gemini(user_text)\n",
    "            print(\"\\nðŸ§  Gemini:\\n\", ai_text)\n",
    "            \n",
    "            # SPEAK OUT RESPONSE + SAVE AUDIO\n",
    "            speak_elevenlabs(ai_text)\n",
    "            \n",
    "        time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd04bfe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¤ Recording voice for 5 seconds...\n",
      "ðŸŽ§ Listening for 'computer'... Speak the wake word anytime.\n",
      "||PaMacCore (AUHAL)|| Error on line 2523: err='-50', msg=Unknown Error\n",
      "||PaMacCore (AUHAL)|| Error on line 2523: err='-50', msg=Unknown Error\n",
      "\n",
      "âœ… Wake word detected!\n",
      "ðŸ“¡ Whisper API status: 200\n",
      "ðŸ“¨ Whisper API raw response: {\"text\":\" you\"}\n",
      "ðŸ“ Transcribed:  you\n",
      "Gemini API status: 200\n",
      "\n",
      "ðŸ§  Gemini:\n",
      " As a large language model, I don't have personal experiences, feelings, or a sense of self in the way humans do.  I don't have a \"you\" in the same way you do.  My purpose is to process information and respond to your requests in a helpful and informative way.\n",
      "\n",
      "How can I help you today?\n",
      "\n",
      "âœ… Audio saved as: ai_response_20250710_091731.mp3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m wake_thread.start()\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Start AI pipeline loop (main thread)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mrun_ai_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mrun_ai_pipeline\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     22\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mðŸ§  Gemini:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, ai_text)\n\u001b[32m     24\u001b[39m     \u001b[38;5;66;03m# SPEAK OUT RESPONSE + SAVE AUDIO\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     \u001b[43mspeak_elevenlabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mai_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m time.sleep(\u001b[32m1\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mspeak_elevenlabs\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m     33\u001b[39m         audio_data = f.read(dtype=\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     34\u001b[39m         sd.play(audio_data, samplerate=f.samplerate)\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m         \u001b[43msd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     37\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâŒ ElevenLabs API failed:\u001b[39m\u001b[33m\"\u001b[39m, response.status_code)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sounddevice.py:398\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(ignore_errors)\u001b[39m\n\u001b[32m    382\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Wait for `play()`/`rec()`/`playrec()` to be finished.\u001b[39;00m\n\u001b[32m    383\u001b[39m \n\u001b[32m    384\u001b[39m \u001b[33;03mPlayback/recording can be stopped with a `KeyboardInterrupt`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    395\u001b[39m \n\u001b[32m    396\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _last_callback:\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_last_callback\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_errors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sounddevice.py:2653\u001b[39m, in \u001b[36m_CallbackContext.wait\u001b[39m\u001b[34m(self, ignore_errors)\u001b[39m\n\u001b[32m   2647\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Wait for finished_callback.\u001b[39;00m\n\u001b[32m   2648\u001b[39m \n\u001b[32m   2649\u001b[39m \u001b[33;03mCan be interrupted with a KeyboardInterrupt.\u001b[39;00m\n\u001b[32m   2650\u001b[39m \n\u001b[32m   2651\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2652\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2653\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2654\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   2655\u001b[39m     \u001b[38;5;28mself\u001b[39m.stream.close(ignore_errors)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py:634\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    632\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    633\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m634\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py:334\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    333\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    335\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    336\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Wake word detected!\n",
      "\n",
      "âœ… Wake word detected!\n",
      "\n",
      "âœ… Wake word detected!\n",
      "\n",
      "âœ… Wake word detected!\n",
      "\n",
      "âœ… Wake word detected!\n"
     ]
    }
   ],
   "source": [
    "# Start wake word detection in a background thread\n",
    "wake_thread = threading.Thread(target=start_wake_word_listener)\n",
    "wake_thread.daemon = True\n",
    "wake_thread.start()\n",
    "\n",
    "# Start AI pipeline loop (main thread)\n",
    "run_ai_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fcfd14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
